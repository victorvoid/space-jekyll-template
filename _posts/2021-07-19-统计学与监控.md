---
layout: post
title:  "统计学与监控"
image: ''
date:   2021-07-19 23:45
tags:
- 
description: ''
categories:
- Network
---

# 均值（Mean Value）

很多时候大家喜欢使用均值来监控请求延时，主要在于其更好计算。对于数据集X=[x1, ..., xn]，均值的计算如下：
```python
mean(X): 
    return sum(X) / len(X)
```
对一个在线服务，我们通常需要时刻刷新均值但又要限制内存使用量，一般采用下面的算法：
```python
mean(x):
    total += x
    n += 1
    return total/n
```
只需要维护total和n两个值，然后不断更新即可计算出当前的均值。

但这种方法对于一个长期运行的程序，会遇到一个麻烦：数值翻转(total通常要比更快翻转）。因此更科学的方法应该使用[Cumulative Moving Average](https://en.wikipedia.org/wiki/Moving_average)方法：
```python
mean(x) : 
    n += 1
    avg += (x - avg)/n
    return avg
```
现在n依然可能翻转，但其翻转速度已经足够慢。

均值问题在于很容易受到极端值的影响，比如一下两组数据：
```
X1 = [2, 8, 4, 1, 5, 10，3，4，7，6]
X2 = [2, 20, 1, 2, 2, 3，3，2，7，8]
```
两组数据的均值都是5，我们通过平均值很难发现X2存在存在一个20这样的异常值。

对于请求延时这样的监控指标，通常延时都稳定在一个区间，我们更关心当出现少量异常大的值时，我们能否快速感知到，而显然平均值时无法满足这一要求。


# φ分位数（φ-quantiles）
我们在指定SLA时，请求延时会被要求限定在一个区间，比如“99.7%的请求会在200ms内返回”。

如何来判断是否满足SLA呢，通常我们使用φ-quantiles来计算99.7%的请求延时都满足的上限(upperBound)。

φ-quantiles

> 把n个数字按照从小到大的顺序排列成一个有序序列L，rank值为φn的那个数据点就称为L的φ-quantile，这里 φ ∈ [0, 1]

但实际我们并没有足够大的内存来完成上述操作，同时O(n)的时间复杂度也不足够好。所以实际工程中会使用那些存在一定误差，但时间复杂度和空间复杂度都足够低的方法。

通常我们基于Histogram（直方图）来计算φ-quantiles。

Histogram是这样一种数据结构，首先它有一个取值范围[MinVal, MaxVal]，然后再取值范围内按照一定步长将取值区间换分为多个Bin/Bucket（桶），每个桶记录分布到该区间数值的个数。

实际上Histogram对应于统计学中的Probability Density Function（概率密度函数）。当数据足够多，桶的分布足够合理，就可以计算出误差很小的φ-quantiles（经验显示可以控制在百分之1）。

如何计算φ-quantiles

φ的值理论上可以是任意0-1直接任意一个值，显然Quantile的值很有可能落在两个Bin之间。

Prometheus采用Linear interpolation（线性插值）来计算Quantile。线性插值首先假设数据的分布是线性的，如果x处于一组相邻的数据(x1, y1)和(x2, y2)之间求对应的y值，则首先算出相邻数据的slop（斜率），然后再使用point-slop（点斜）式计算出y值：
```python
linear_interpolation_point(x1, y1, x2, y2, x):
    slop = (y2-y1)/(x2-x1)
    return slop(x-x1)+y1
```
再去看promql/quantile.go的bucketQuantile()就豁然开朗了：

    return bucketStart + (bucketEnd-bucketStart)*(rank/count) 
# Bucket Range
影响φ-quantiles计算精度的一个因素可能并不是那么明显：桶距。

我们假设请求延时通常在200-300ms之间，某些长尾请求可能多达1.5s，那么一个合理的取值范围可能会设置为[200, 2000]。如果桶距设为100（这当然是一个比较糟糕的选择，但我们这里用来简化计算），那么通常请求会落入第一个桶{le="0.3"}。

根据上面公式我们可以发现，无论实际的延时分布是怎样的，得到的p95结果都将是：295ms！

考虑到延时类的实际分布情况，合理的桶距，应该是靠近MinVal侧桶距较小，而靠近MaxVal一侧桶距较大。具有这种特点的Histogram被称为Linear Histogram。

下面是一种可能的实现：

init_bucket_range(minVal, maxVal, bucket_count)
    log_max = log(maximum)
    bucket_index = 1
    current = minVal
    ranges[bucket_index] = current
    while (bucket_count > ++bucket_index)
    {
        log_current = log(current)
        log_ratio = (log_max - log_current) / (bucket_count - bucket_index);
        log_next = log_current + log_ratio
        next = (floor(exp(log_next) + 0.5))
        if (next > current)
            current = next
        else
            ++current
        ranges[bucket_index] = current
    }
这个算法能比较好的保证桶距在左侧分布较密，右侧分布稀疏。

除此以外，HdrHistogram也提供了一种类似算法(n-significant-digitas)，感兴趣的同学可以


p95是否太过灵敏？
从原理上了解了φ-quantiles的计算之后，我们再来看看实际应用中的一些问题。

通常我们会监控0.95-quantiles和0.50-quantiles，一般我们成为95线/50线，或者又记为p95/p50。

从均值转为使用p95来监控延时之后，会出现平均延时还没有显著变化但p95已经快速升高报警，这时难免有人会质疑，p95是不是太灵敏了，我们是不是在小题大做？

很遗憾的是，p95其实还不够灵敏。

常规情况我们假设延时在200-400ms，当延时大于400ms时我们认为延时过高，那么当延时高过1s时，这时究竟有多大影响？只有5%吗？很遗憾，通常这个影响要远大于5%。

以搜索为例，当我们检索到结果后，对于热词，我们通常第一次查询就能得到比较理想的结果，对长尾词，有很大可能我们会继续翻页。平均下来，每次检索我们可能需要多次查询。如果平均需要2次查询，那大概有10%(1- 0.95^2= 0.10)的用户会遇到慢查询，如果是4次查询，那就会有20%(1-0.95^4 = 0.2)的用户会遇到慢查询！

如果你希望第一时间发现故障，显然p95都不足够灵敏了，你应该使用p99.9

结语
除了请求延时等基础监控，我们还可以利用概率方法实现Anomaly Detection，在第一时间去发现线上的各种性能异常甚至行为异常。相信未来Data Science团队会跟Operation团队进一步融合，并改变整个Monitor/Alert Ecosystem。